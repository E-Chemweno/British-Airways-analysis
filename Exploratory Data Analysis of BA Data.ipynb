{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!pip install plotly\n",
    "#!pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import Pandas library for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Import NumPy library for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Import OS library for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Import Matplotlib library for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Seaborn library for statistical data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Plotly Express library for interactive plotting\n",
    "import plotly.express as px\n",
    "\n",
    "# Import datetime module for working with dates and times\n",
    "import datetime as dt\n",
    "\n",
    "# Import WordCloud and STOPWORDS from the wordcloud library for creating word clouds\n",
    "from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Read the CSV file into a DataFrame, specifying the first column as the index\n",
    "df = pd.read_csv(cwd + \"/cleaned-BA-reviews.csv\", index_col=0)\n",
    "\n",
    "# Reset the index of the DataFrame and drop the existing index\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Displayes the first few rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the average overall rating given for British Airways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.stars.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the total counts for each ratings?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already imported pandas and have a DataFrame named 'df'\n",
    "\n",
    "# Plot the distribution of ratings\n",
    "df.stars.value_counts().plot(kind=\"bar\")\n",
    "plt.xlabel(\"Ratings\")\n",
    "plt.ylabel(\"Total Number of reviews with that rating\")\n",
    "plt.title(\"Counts for each rating\")  # Changed 'suptitle' to 'title'\n",
    "#plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_ratings = pd.DataFrame(df['stars'].value_counts())\n",
    "pct_values = (df_ratings['stars'].values / df_ratings['stars'].values.sum() * 100).tolist()\n",
    "pct_values = [round(x, 2) for x in pct_values]\n",
    "df_ratings['pct_values'] = pct_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all reviews into a single string\n",
    "reviews = \" \".join(df.corpus)\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Define a set of English stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Create and generate a word cloud image\n",
    "wordcloud = WordCloud(height=600, width=600, max_font_size=100, max_words=500, stopwords=stopwords).generate(reviews)\n",
    "\n",
    "# Display the generated word cloud image\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many words that does not set the idea of whether the review is positive or negative. For example words like \"passenger\", \"flight\", etc. does not add conlcusive value hence we can include them in stopwords list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "reviews = \" \".join(df.corpus)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stopwords.update([\"ba\",\"flight\", \"british\",\"airway\", \"airline\",\"plane\", \"told\",\"also\",\"passenger\" \\\n",
    "                 \"london\", \"heathrow\", \"aircraft\", \"could\",\"even\", \"would\"])\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(height=500,width=500,max_font_size=100, max_words=300, stopwords=stopwords).generate(reviews)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the text of all reviews into a list of words\n",
    "words = reviews.split(\" \")\n",
    "\n",
    "# Remove certain words that will not be used to determine the positive or negative sentiment\n",
    "stopwords = text.ENGLISH_STOP_WORDS.union(['flight', 'ba', \"passenger\", \"u\", \"london\", \"airway\", \"british\", \"airline\", \\\n",
    "                                           \"heathrow\", \"plane\", \"lhr\", \"review\"])\n",
    "\n",
    "new_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "# Calculate the frequency distribution of the words\n",
    "nlp_words = FreqDist(new_words).most_common(20)\n",
    "\n",
    "# Create a DataFrame of these words and their frequencies\n",
    "all_fdist = pd.Series(dict(nlp_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Setting figure and axis into variables\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Seaborn plotting using Pandas attributes + xtick rotation for ease of viewing\n",
    "all_plot = sns.barplot(x=all_fdist.index, y=all_fdist.values, ax=ax)\n",
    "\n",
    "# Add labels to the bars\n",
    "all_plot.bar_label(all_plot.containers[0])\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a glimpse of what customers are really talking about here. We see that Seat is most talked about the airline followed by \"Service\" and \"food\" which are all very important to customers in terms of service. However, we still do not know is how they are expressing about each of this service. To bring some significane to these terms we will use ngram plots to see if they are bad or good in experience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency with N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import nltk.collocations as collocations\n",
    "from nltk import FreqDist, bigrams\n",
    "\n",
    "# Combine all reviews into a single string\n",
    "reviews = \" \".join(df.corpus)\n",
    "\n",
    "# Split the text of all reviews into a list of words\n",
    "words = reviews.split(\" \")\n",
    "\n",
    "# Remove stopwords\n",
    "new_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "# Function to get frequency distribution of n-grams and plot\n",
    "def get_freq_dist(new_words, number_of_ngrams):\n",
    "    from nltk import ngrams\n",
    "    \n",
    "    # Generate n-grams\n",
    "    ngrams_list = ngrams(new_words, number_of_ngrams)\n",
    "\n",
    "    # Create FreqDist\n",
    "    ngram_fd = FreqDist(ngrams_list).most_common(40)\n",
    "\n",
    "    # Sort values by highest frequency\n",
    "    ngram_sorted = {k: v for k, v in sorted(ngram_fd, key=lambda item: item[1])}\n",
    "\n",
    "    # Join n-gram tokens with '_' and maintain sorting\n",
    "    ngram_joined = {'_'.join(k): v for k, v in sorted(ngram_fd, key=lambda item: item[1])}\n",
    "\n",
    "    # Convert to Pandas Series for easy plotting\n",
    "    ngram_freqdist = pd.Series(ngram_joined)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = ngram_freqdist.plot(kind=\"barh\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# Call the function with new_words and the desired number of n-grams (in this case, 4)\n",
    "get_freq_dist(new_words, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are very common positive terms regarding cabin crew. For example, cabin_crew_friendly_helpful, cabin_crew_friendly_attentive, cabin_crew_friendly_efficient, etc. So certainly customers are providing good reviews about cabin crew staff of British Airways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.12.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ratings_1_3 = df[df.stars.isin([1,2,3])]\n",
    "ratings_4_6 = df[df.stars.isin([4,5,6])]\n",
    "ratings_7_10 = df[df.stars.isin([7,8,9,10])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
